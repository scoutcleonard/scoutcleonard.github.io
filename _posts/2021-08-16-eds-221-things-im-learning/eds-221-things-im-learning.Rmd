---
title: "EDS 221: Things I'm Learning!"
categories:
  - course reflections
description: |
  A reflection on all the things I'm learning in my first weeks of graduate school.
author:
  - name: Scout Leonard
    url: {https://scoutcleonard.github.io}
date: 08-16-2021
output:
  distill::distill_article:
    self_contained: false
preview: images/meds_photo.jpg
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(palmerpenguins)
```

## **I'm learning lots in Environmental Data Science 221: Scientific Programming Essentials!**

Here are some examples of things I've learned so far: 

One **function** we've learned that I enjoy is the `case_when()` function. When paired with the `mutate()` function, we can sort data in a newly created column based on existing data. Below is an example with the Palmer Penguins dataset. 

```{r fig.alt="Bar graph comparing the flipper length in millimeters of 3 species of penguin: Adelie, Chinstrap, and Gentoo. The flipper sizes are binned to small and large sizes and the proportions of small and large flippers are seen in each bar."}
case_example <- penguins %>% 
  mutate(binned_flipper_size = case_when(
    flipper_length_mm < 185 ~ "small", 
    flipper_length_mm >= 185 ~ "medium"
  ))


ggplot(data = case_example, aes(x = species, y = flipper_length_mm, fill = binned_flipper_size)) +
  geom_col(position = "fill") +
  labs(title = "Playing with case_when(), a graphic example!") +
  theme_minimal()
```
I made this stacked bar graph so you can see that I have a new column that has two classifications for flipper length: *medium* and *small*.

A **concept** we've learned in EDS 221 is tidy data. As an organizational fiend, this has been one of my favorite concepts! I have worked on many, many untidy spreadsheets over the years. In tidy data, data is organized in a predictable way! Most importantly, tidy data has: 

1.) Each variable is a column.
2.) Each observation is a row. 
3.) Each cell contains **1** value. 

A **~thing~** I have learned about doing data science is that reproducible workflows are essential, and acheived in various ways! Valuing the code over the product (i.e. saving and pushing to repo) is more important that the output (html you knit!). Create a repo and stage, commit, push, pull early and often! Try not to copy and paste code. Be aware of the order in which you put functions. Do not alter your original data set. There are many more, but as you can see, reproducible workflows are **essential.**



Distill is a publication format for scientific and technical writing, native to the web.

Learn more about using Distill at <https://rstudio.github.io/distill>.


